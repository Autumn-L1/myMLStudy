{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "# 核心函数\n",
    "保存模型`torch.save(arg, PATH)`\n",
    "加载模型`torch.load(PATH)`\n",
    "# 基本实现\n",
    "保存和加载一个完整的模型\n",
    "```python\n",
    "torch.save(model, PATH)\n",
    "\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    " ```\n",
    "其中PATH是保存模型的路径（到文件名），例如\n",
    "```python\n",
    "FILE = 'model.pth'\n",
    "torch.save(model, FILE)\n",
    " ```\n",
    "。\n",
    "\n",
    "保存和加载一个模型的参数（加载时需要重新实例化一个模型对象）\n",
    " ```python\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    " ```\n",
    "\n",
    "# 检查点\n",
    "创造一个检查点\n",
    "```python\n",
    "checkpoint{\n",
    "    \"epoch\":90,\n",
    "    \"model_state\":model.state_dict(),\n",
    "    \"optim_state\":optimizer.state_dict()\n",
    "}\n",
    "torch.save(checkpoint,\"checkpoint.pth\")\n",
    "```\n",
    "加载检查点\n",
    "```python\n",
    "loaded_checkpoint=torch.load(\"checkpoint.pth\")\n",
    "\n",
    "epoch=loaded_checkpoint[\"epoch\"]\n",
    "\n",
    "model=Model(n_input_features=6)\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0)\n",
    "\n",
    "model.load_state_dict(checkpoint [\"model_state\"])\n",
    "optimizer.load_state_dict(checkpoint [\"optim_state\"])\n",
    "```\n",
    "\n",
    "# 加载时Device的转换\n",
    "使用torch.load()方法，以及其map_location参数\n",
    "```python\n",
    "#Save on GPU,Load on GPU\n",
    "device=torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(),PATH)\n",
    "\n",
    "model=Model(*args,**kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)\n",
    "\n",
    "#Save on GPU,Load on CPU\n",
    "device=torch.device(\"cuda\")\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(),PATH)\n",
    "\n",
    "device=torch.device('cpu')\n",
    "model=Model(*args,**kwargs)\n",
    "model.load_state_dict(torch.load(PATH,map_location=device))\n",
    "\n",
    "#Save on CPU,Load on GPU\n",
    "torch.save(model.state_dict(),PATH)\n",
    "device=torch.device(\"cuda\")\n",
    "model=Model(*args,**kwargs)\n",
    "model.load_state_dict(torch.load(PATH,map_location=\"cuda:0\"))#Choose whatever GPU you want\n",
    "model.to(device)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "99559e50fbd98836"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "477526a447116df7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
