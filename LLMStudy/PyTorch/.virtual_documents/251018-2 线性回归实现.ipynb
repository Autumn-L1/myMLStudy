


#1)Design model(input,output size,forward pass)
#2)Construct loss and optimizer
#3)Trainingtoop
# -forward pass:compute prediction and loss
# -backward pass: gradients
# - updateweights
import torch
import torch.nn as nn
import numpy as np
from sklearn import datasets
import matplotlib.pyplot as plt


#0) prepare data
X_numpy, Y_numpy =  datasets.make_regression(n_samples = 100, n_features = 1, noise = 20, random_state =1)

X = torch.from_numpy(X_numpy.astype(np.float32))
y = torch.from_numpy(Y_numpy.astype(np.float32))

y = y.view(y.shape[0], 1) #一行多列->一列多行


n_samples, n_features= X.shape
print(n_samples, n_features)


#1) model
input_size = n_features
output_size = 1
model = nn.Linear(input_size, output_size)


# 2) loss and optimize
lr = 0.01
criterion = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=lr)


# training loop
num_epoch = 100
for epoch in range(num_epoch):
	# -forward pass:compute prediction and loss
	y_pred = model(X)
	loss = criterion(y_pred, y)
	# -backward pass: gradients
	loss.backward()
	# -updateweights
	optimizer.step()
	optimizer.zero_grad()
	
	# show loss
	if epoch%10==0:
		print(f'epoch {epoch+1} loss = {loss:.8f}')

#plot
predicted = model(X).detach().numpy()
plt.plot(X_numpy,Y_numpy,'ro')
plt.plot(X_numpy,predicted,'b')
